<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ITCS Workshop</title>
    <script>
        MathJax = {
            tex: {
                    inlineMath: [['$', '$'], ['\\(', '\\)']],
                    macros: {
                        avgq: '{\\mathrm{avgq}}',
                        wt: '{\\mathrm{wt}}',
                        }
                },
            svg: {
                fontCache: 'global'
                }
        };
    </script>
    <script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
    </script>
    <link rel="stylesheet" href="style.css">
    <script src="script.js" defer></script>
</head>
<body>
    <nav class="show">
        <ul>
            <li><a href="#home">é¦–é¡µ</a></li>
            <li><a href="#summary">æ´»åŠ¨èƒŒæ™¯</a></li>
            <li><a href="#schedule">æ—¥ç¨‹å®‰æ’</a></li>
            <li><a href="#speaker">ä¸»è®²å˜‰å®¾</a></li>
            <li><a href="#organization">ç»„ç»‡æœºæ„</a></li>
        </ul>
    </nav>
    <h1 style="padding-top: 100px;" id="home">ITCS Workshop</h1>
    <div class="content" id="summary">
        <div style="height: 50px;"></div>
        <h2>æ´»åŠ¨èƒŒæ™¯</h2>
        <p>
            2016å¹´6æœˆ18æ—¥ï¼Œä¸Šæµ·è´¢ç»å¤§å­¦ç†è®ºè®¡ç®—æœºç§‘å­¦ç ”ç©¶ä¸­å¿ƒ (ITCS) æ­£å¼æˆç«‹ï¼Œè½¬çœ¼å·²è¿æ¥ä¹å‘¨å¹´ã€‚å€¼æ­¤å‘¨å¹´åº†å…¸ä¹‹é™…ï¼Œä¸­å¿ƒç‰¹ä¸¾åŠç†è®ºè®¡ç®—æœºå­¦æœ¯ç ”è®¨ä¼šï¼Œè¯šé‚€å„ä½æ–°è€æœ‹å‹ç›¸èšäº¤æµï¼Œå…±åŒåº†ç¥ITCSçš„ä¹å²ç”Ÿæ—¥ï¼
        </p>
        <!-- <div class="image-slider">
            <div class="slider-container">
                <img src="img/bg1.png" alt="Conference Image 1">
                <img src="img/bg2.png" alt="Conference Image 2">
                <img src="img/bg3.png" alt="Conference Image 3">
            </div>
        </div> -->
        <p>
            ğŸ“… æ´»åŠ¨æ—¶é—´ï¼š2025å¹´6æœˆ14æ—¥-15æ—¥<br>
            ğŸ“ æ´»åŠ¨åœ°ç‚¹ï¼šä¸Šæµ·è´¢ç»å¤§å­¦<br>
        </p>

        <div class="schedule" id="schedule">
            <div style="height: 50px;"></div>
            <h2>æ—¥ç¨‹å®‰æ’ (2025 å¹´ 6 æœˆ 14 - 15 æ—¥)</h2>
            <div class="day" onclick="toggleDetails('day1')">6 æœˆ 14 æ—¥ä¸Šåˆ</div>
            <div id="day1" class="details-content show">
                <table border="1" cellspacing="0" cellpadding="5">
                    <tr>
                        <th>æ—¶é—´</th>
                        <th>æŠ¥å‘Šäºº</th>
                        <th>æŠ¥å‘Šå†…å®¹</th>
                        <th>ä¸»æŒäºº</th>
                    </tr>
                    <tr>
                        <td class="time-cell">09:00-09:40</td>
                        <td class="no-wrap">å¼ å®‡æ˜Š</td>
                        <td>Online Flow TimeMinimization: Tight Bounds for Non-Preemptive Algorithms</td>
                        <td rowspan="2">ä¼è™</td>
                    </tr>
                    <tr>
                        <td class="time-cell">09:40-10:10</td>
                        <td class="no-wrap">è´ºçƒˆ</td>
                        <td>Towards Robust and Efficient Large-Scale Stochastic Optimization</td>
                    </tr>
                    <tr>
                        <td class="time-cell">10:10-11:00</td>
                        <td colspan="3"><strong>èŒ¶æ­‡</strong></td>
                    </tr>
                    <tr>
                        <td class="time-cell">11:00-11:30</td>
                        <td class="no-wrap">å´æ—‹</td>
                        <td>Robust Sparsification via Sensitivity</td>
                        <td rowspan="2">ç‹æ™“</td>
                    </tr>
                    <tr>
                        <td class="time-cell">11:30-12:00</td>
                        <td class="no-wrap">å§œå°‘å³°</td>
                        <td>Local Search for Clustering in Almost-linear Time</td>
                    </tr>
                    <tr>
                        <td class="time-cell">12:00-14:00</td>
                        <td colspan="2"><strong>åˆé¤</strong></td>
                        <td class="no-wrap">æ•™å·¥é£Ÿå ‚</td>
                    </tr>
                </table>
            </div>

            <div class="day" onclick="toggleDetails('day2')">6 æœˆ 14 æ—¥ä¸‹åˆ</div>
            <div id="day2" class="details-content show">
                <table border="1" cellspacing="0" cellpadding="5">
                    <tr>
                        <th>æ—¶é—´</th>
                        <th>æŠ¥å‘Šäºº</th>
                        <th>æŠ¥å‘Šå†…å®¹</th>
                        <th>ä¸»æŒäºº</th>
                    </tr>
                    <tr>
                        <td class="time-cell">14:00-14:30</td>
                        <td class="no-wrap">æ®µç„¶</td>
                        <td>Breaking the Sorting Barrier for Directed Single-Source Shortest Paths</td>
                        <td rowspan="3">å”å¿—çš“</td>
                    </tr>
                    <tr>
                        <td class="time-cell">14:30-15:00</td>
                        <td class="no-wrap">é™ˆç¿Œä½³</td>
                        <td>Understand uncolored CFI-graphs</td>
                    </tr>
                    <tr>
                        <td class="time-cell">15:00-15:30</td>
                        <td class="no-wrap">èµµæ™—</td>
                        <td>Revisiting Scalarization in Multi-Task Learning</td>
                    </tr>
                    <tr>
                        <td class="time-cell">15:30-16:30</td>
                        <td colspan="3"><strong>èŒ¶æ­‡ & é›†ä½“ç…§</strong></td>
                    </tr>
                    <tr>
                        <td class="time-cell">16:30-17:00</td>
                        <td>æ¢å®µ</td>
                        <td>Simulation-Based Cryptographic Security in a Quantum Era</td>
                        <td rowspan="3">é™¶äº¦å¿ƒ</td>
                    </tr>
                    <tr>
                        <td class="time-cell">17:00-17:30</td>
                        <td>æå…ƒ</td>
                        <td>Average-Case Deterministic Query Complexity of Boolean Functions with Fixed Weight</td>
                    </tr>
                    <tr>
                        <td class="time-cell">17:30-18:00</td>
                        <td>é™ˆé›ª</td>
                        <td>Sparse LPN and Refuting random XORs</td>
                    </tr>
                    <tr>
                        <td class="time-cell">18:00-20:00</td>
                        <td colspan="2"><strong>æ™šé¤</strong></td>
                        <td class="no-wrap">æ•™å·¥é£Ÿå ‚</td>
                    </tr>
                </table>
            </div>

            <div class="day" onclick="toggleDetails('day3')">6 æœˆ 15 æ—¥ä¸Šåˆ</div>
            <div id="day3" class="details-content show">
                <table border="1" cellspacing="0" cellpadding="5">
                    <tr>
                        <th>æ—¶é—´</th>
                        <th>æŠ¥å‘Šäºº</th>
                        <th>æŠ¥å‘Šå†…å®¹</th>
                        <th>ä¸»æŒäºº</th>
                    </tr>
                    <tr>
                        <td class="time-cell">09:00-09:30</td>
                        <td class="no-wrap">éŸ©æº</td>
                        <td>TripleEagle: Simple, Fast and Practical Budget-Feasible Mechanisms for Submodular Valuations</td>
                        <td rowspan="2">éƒ­å­è¶…</td>
                    </tr>
                    <tr>
                        <td class="time-cell">09:30-10:00</td>
                        <td class="no-wrap">å†¯é€¸ä¸</td>
                        <td>Persuasive Calibration</td>
                    </tr>
                    <tr>
                        <td class="time-cell">10:00-11:00</td>
                        <td colspan="3"><strong>èŒ¶æ­‡</strong></td>
                    </tr>
                    <tr>
                        <td class="time-cell">11:00-11:30</td>
                        <td class="no-wrap">æå¸…</td>
                        <td>Optimal Algorithm for Max-Min Fair Bandit</td>
                        <td rowspan="2">å¾éŸ§å–†</td>
                    </tr>
                    <tr>
                        <td class="time-cell">11:30-12:00</td>
                        <td class="no-wrap">é‡‘è€€æ¥ </td>
                        <td>Tight regret bounds for fixed price bilateral trade</td>
                    </tr>
                    <tr>
                        <td class="time-cell">12:00-14:00</td>
                        <td colspan="2"><strong>åˆé¤</strong></td>
                        <td class="no-wrap">æ•™å·¥é£Ÿå ‚</td>
                    </tr>
                </table>
            </div>

        </div>
        
        <div class="speaker" id="speaker">
            <div style="height: 50px;"></div>
            <h2>ä¸»è®²å˜‰å®¾</h2>
            <h3 >6 æœˆ 14 æ—¥ ä¸Šåˆ</h3>
            <h4>ï¼ˆä¸€ï¼‰09:10-09:40 å¼ å®‡æ˜Šï¼ˆä¸Šæµ·äº¤é€šå¤§å­¦ï¼‰</h4>
            <h4 style="font-weight: normal;"><strong>Title</strong>: Online Flow Time Minimization: Tight Bounds for Non-Preemptive Algorithms</h4>
            <div class="day" onclick="toggleDetails('day29')">Abstract</div>
            <div id="day29" class="details-content">
                <p>
                    This paper studies the online scheduling problem of minimizing the total flow time for $n$ jobs arriving online on $m$ identical machines. While the problem is well understood in the preemptive setting, prior work often asserts that preemption or resource augmentation is necessary, based on the $\Omega(n)$ lower bound shown by Kellerer, Tautenhahn, and Woeginger (SICOMP 1999) for deterministic non-preemptive algorithms in the single-machine case.  However, this lower bound applies only to deterministic algorithms in the single-machine case and leaves several fundamental questions unanswered: What is the best deterministic competitive ratio when $m > 1$? Can randomness improve performance in the non-preemptive setting? We address both questions. We present a deterministic non-preemptive algorithm with a competitive ratio of $O(n/m^2 + \sqrt{n/m} \log m)$ and prove that this is nearly tight with a lower bound of $\Omega(n/m^2 + \sqrt{n/m})$. Additionally, we provide a randomized non-preemptive algorithm with a competitive ratio of $O(\sqrt{n/m})$ and prove its tightness, surpassing the $\Omega(n)$ bound in the $m = 1$ case.  We also consider the intermediate model of kill-and-restart, where interrupted jobs must restart from scratch. For $m = 1$, we prove an $\Omega(n / \log n)$ lower bound. Interestingly, the situation changes drastically once $m \geq 2$: we develop a deterministic $O(\sqrt{n/m})$-competitive algorithm, which is tight even among randomized algorithms. Since our algorithms run in polynomial time, they improve the best-known offline approximation ratio from $O(\sqrt{n/m} \log(n/m))$ to $O(\sqrt{n/m})$.
                </p>
            </div>
            <div class="day" onclick="toggleDetails('day100')">Bio</div>
            <div id="day100" class="details-content">
                <p>
                     Yuhao zhang is an Associate Professor of John Hopcroft Center for Computer Science at Shanghai Jiao Tong University since 2021, working in the field of theoretical computer science. He obtained his Ph.D. (2016~2020) from the Department of Computer Science at the University of Hong Kong, supervised by Dr. Zhiyi Huang. Before that, he got his B.E. from the College of Computer Science and Technology at Zhejiang University (2012~2016). During his undergraduate study, he started to be interested in theoretical computer science when he joined the research group of Prof. Guochuan Zhang. His research focuses on Online Algorithms and Approximation Algorithms. He is dedicated to designing algorithms with provable guarantees for real-world applications and advancing general mathematical frameworks for analyzing their performance.
                </p>
             </div>

            <h4>ï¼ˆäºŒï¼‰09:40-10:10 è´ºçƒˆï¼ˆä¸Šæµ·è´¢ç»å¤§å­¦ï¼‰</h4>
            <h4 style="font-weight: normal;"><strong>Title</strong>:Towards Robust and Efficient Large-Scale Stochastic Optimization</h4>
            <div class="day" onclick="toggleDetails('day5')">Abstract</div>
            <div id="day5" class="details-content">
                <p>
                    The rapid advancements in machine learning have been driven by increasingly large datasets and growing computational power. Developing optimization algorithms that scale effectively with data size and the number of computing machines is critical but fraught with challenges, including computational bottlenecks and communication overhead. Additionally, large-scale stochastic optimization processes are inherently vulnerable to adversaries, such as corrupted training samples or compromised machines, which can significantly degrade model performance without robust safeguards. In this talk, I will delve into the dual challenges of efficiency and robustness in large-scale machine learning problems and present our recent work in addressing these issues, including novel approaches to scalable and resilient optimization.
                </p>
            </div>
            <div class="day" onclick="toggleDetails('day101')">Bio</div>
            <div id="day101" class="details-content">
                <p>
                    â€‹â€‹Lie Heâ€‹â€‹ is an Assistant Professor in the School of Computing and Artificial Intelligence at Shanghai University of Finance and Economics (SUFE). He received his bachelor's degree from the University of Science and Technology of China (USTC), as well as an master's and doctoral degree in Computer Science from the Ã‰cole Polytechnique FÃ©dÃ©rale de Lausanne (EPFL), Switzerland, advised by Prof. Martin Jaggi. His research centers on â€‹â€‹efficient large-scale stochastic optimizationâ€‹â€‹ with â€‹â€‹robustness guarantees against training-time adversariesâ€‹â€‹ and uncertainty quantifications.
                </p>
            </div>

            <h4>ï¼ˆä¸‰ï¼‰11:10-11:40 å´æ—‹ï¼ˆå—æ´‹ç†å·¥å¤§å­¦ï¼‰</h4>
            <h4 style="font-weight: normal;"><strong>Title</strong>:Robust Sparsification via Sensitivity</h4>
            <div class="day" onclick="toggleDetails('day7')">Abstract</div>
            <div id="day7" class="details-content">
                The existence of outliers presents formidable challenges for many machine learning problems, including clustering, subspace embedding, and low-rank approximation. In this work, we consider robust coresets for all the above machine learning problems, which reduce the input dataset into a small subset, thus providing a scalable and robust solution. We design a general framework to construct a robust coreset for any machine learning problem that admits a bounded total sensitivity and vanilla coreset. Our coreset is near-optimal for subspace embedding. Our experimental results show that our coresets outperform the uniform sampling benchmark on real-world data sets. This is a joint work with Chansophea Wathanak In, Yi Li, and David Woodruff.
            </div>
            <div class="day" onclick="toggleDetails('day102')">Bio</div>
            <div id="day102" class="details-content">
                <p>
                    Xuan Wu is a research fellow in Nanyang Technological University, working with Yi Li. He earns his Ph.D from Johns Hopkins Universitiy, adviced by Vladimir Braverman. Before working in NTU, he has worked as a full time researcher in Huawei, headed by Pinyan Lu. Xuan Wu's research focuses on sparsification for machine learning problem, in particular coresets for clustering.
                </p>
            </div>

            <h4>ï¼ˆå››ï¼‰11:40-12:10 å§œå°‘å³°ï¼ˆåŒ—äº¬å¤§å­¦ï¼‰</h4>
            <h4 style="font-weight: normal;"><strong>Title</strong>:Local Search for Clustering in Almost-linear Time</h4>
            <div class="day" onclick="toggleDetails('day9')">Abstract</div>
            <div id="day9" class="details-content">
                We propose the first local search algorithm for Euclidean clustering that attains an $O(1)$-approximation in almost-linear time. Specifically, for Euclidean k-Means, our algorithm achieves an $O(c)$-approximation in $\tilde{O}(n^{1 + 1 / c})$ time, for any constant $c \ge 1$, maintaining the same running time as the previous (non-local-search-based) approach [la~Tour and Saulpic, arXiv'2407.11217] while improving the approximation factor from $O(c^{6})$ to $O(c)$.  The algorithm generalizes to any metric space with sparse spanners, delivering efficient constant approximation in $\ell_p$ metrics, doubling metrics, Jaccard metrics, etc.  This generality derives from our main technical contribution: a local search algorithm on general graphs that obtains an $O(1)$-approximation in almost-linear time. We establish this through a new $1$-swap local search framework featuring a novel swap selection rule. At a high level, this rule ``scores'' every possible swap, based on both its modification to the clustering and its improvement to the clustering objective, and then selects those high-scoring swaps. To implement this, we design a new data structure for maintaining approximate nearest neighbors with amortized guarantees tailored to our framework.
            </div>
            <div class="day" onclick="toggleDetails('day103')">Bio</div>
            <div id="day103" class="details-content">
                <p>
                    å§œå°‘å³°åšå£«ç°ä»»åŒ—äº¬å¤§å­¦å‰æ²¿è®¡ç®—ç ”ç©¶ä¸­å¿ƒåŠ©ç†æ•™æˆï¼ŒåŒ—äº¬å¤§å­¦åšé›…é’å¹´å­¦è€…ã€‚ä»–åšå£«æ¯•ä¸šäºé¦™æ¸¯å¤§å­¦ï¼Œå¹¶å…ˆååœ¨ä»¥è‰²åˆ—é­èŒ¨æ›¼ç§‘å­¦é™¢å’ŒèŠ¬å…°é˜¿å°”æ‰˜å¤§å­¦æ‹…ä»»åšå£«åç ”ç©¶å‘˜åŠåŠ©ç†æ•™æˆã€‚ä»–çš„ç ”ç©¶é¢†åŸŸæ˜¯ç†è®ºè®¡ç®—æœºç§‘å­¦ï¼Œä¾§é‡äºç»„åˆä¼˜åŒ–é—®é¢˜çš„å¤§æ•°æ®ç®—æ³•ã€è¿‘ä¼¼ç®—æ³•å’Œåœ¨çº¿ç®—æ³•ã€‚ä»–çš„å¤šç¯‡ç ”ç©¶å‘è¡¨äºSICOMPã€TALGã€STOCã€FOCSã€SODAç­‰ç†è®ºè®¡ç®—æœºç§‘å­¦æ–¹å‘çš„é¡¶çº§æœŸåˆŠä¸ä¼šè®®ä¸Šã€‚
                </p>
            </div>

            
            <h3>6 æœˆ 14 æ—¥ ä¸‹åˆ</h3>

            <h4>ï¼ˆäº”ï¼‰14:00-14:30 æ®µç„¶ï¼ˆæ¸…åå¤§å­¦ï¼‰</h4>
            <h4 style="font-weight: normal;"><strong>Title</strong>:Breaking the Sorting Barrier for Directed Single-Source Shortest Paths</h4>
            <div class="day" onclick="toggleDetails('day11')">Abstract</div>
            <div id="day11" class="details-content">
                We give a deterministic $O(m\log^{2/3}n)$-time algorithm for single-source shortest paths (SSSP) on directed graphs with real non-negative edge weights in the comparison-addition model. This is the first result to break the $O(m+n\log n)$ time bound of Dijkstra's algorithm on sparse graphs, showing that Dijkstra's algorithm is not optimal for SSSP.
            </div>
            <div class="day" onclick="toggleDetails('day104')">Bio</div>
            <div id="day104" class="details-content">
                <p>
                    Ran Duan received his B.S. degree in Computer Science at Tsinghua University in 2006, and his M.S. and Ph.D. degrees in Theoretical Computer Science at University of Michigan, Ann Arbor (under the instruction of Prof. Seth Pettie). ThenÂ he heldÂ a postdoctoral researcher position in Max-Planck-Institut fÃ¼r Informatik in Germany until 2014, supported by Alexander von Humboldt fellowship. In Aug 2014, he becomes a faculty member in IIIS. His research interest focuses on graph algorithms, data structures, and computational theory.
                </p>
            </div>

            <h4>ï¼ˆå…­ï¼‰14:30-15:00 é™ˆç¿Œä½³ï¼ˆä¸Šæµ·äº¤é€šå¤§å­¦ï¼‰</h4>
            <h4 style="font-weight: normal;"><strong>Title</strong>:Understand uncolored CFI-graphs</h4>
            <div class="day" onclick="toggleDetails('day13')">Abstract</div>
            <div id="day13" class="details-content">
                <p>
                    The CFI-graphs, named after Cai, Fuerer, and Immerman,  are central to the study of the graph isomorphism testing and of first-order logic with counting. They are often colored graphs, and the coloring plays a key role in many of their applications. As usual, it is not hard to remove the coloring by some extra graph gadgets, but at the cost of blowing up the size of the graphs and changing some key parameters of the graphs as well. This might lead to suboptimal combinatorial bounds important to their applications. In this talk, I will give a detailed account of the CFI-graphs, both colored and uncolored, and show they serve the same purposes for most applications.  This is joint work with Joerg Flum and Mingjun Liu.
                </p>
            </div>
            <div class="day" onclick="toggleDetails('day105')">Bio</div>
            <div id="day105" class="details-content">
                <p>
                    é™ˆç¿Œä½³ç›®å‰æ˜¯ä¸Šæµ·äº¤é€šå¤§å­¦è®¡ç®—æœºç³»æ•™æˆã€‚ä»–åœ¨ä¸Šæµ·äº¤é€šå¤§å­¦è·å¾—è½¯ä»¶ä¸ç†è®ºä¸“ä¸šåšå£«ã€å¾·å›½å¼—è±å ¡å¤§å­¦æ•°å­¦åšå£«ã€‚ä»–çš„ä¸»è¦ç ”ç©¶å…´è¶£ä¸ºè®¡ç®—æœºä¸æ•°å­¦çš„äº¤å‰é¢†åŸŸï¼ŒåŒ…æ‹¬é€»è¾‘ã€ç®—æ³•ä¸è®¡ç®—å¤æ‚æ€§ã€‚
                </p>
            </div>

            <h4>ï¼ˆä¸ƒï¼‰15:00-15:30 èµµæ™—ï¼ˆUniversity of Illinois Urbana-Champaignï¼‰</h4>
            <h4 style="font-weight: normal;"><strong>Title</strong>:Revisiting Scalarization in Multi-Task Learning</h4>
            <div class="day" onclick="toggleDetails('day15')">Abstract</div>
            <div id="day15" class="details-content">
                <p>
                    Linear scalarization, i.e., combining all loss functions by a weighted sum, has been the default choice in the literature of multi-task learning (MTL) since its inception. In recent years, there has been a surge of interest in developing Specialized Multi-Task Optimizers (SMTOs) that treat MTL as a multi-objective optimization problem. However, it remains open whether there is a fundamental advantage of SMTOs over scalarization. In this talk, I will revisit scalarization from a theoretical perspective. I will be focusing on linear MTL models and studying whether scalarization is capable of fully exploring the Pareto front. Our findings reveal that, in contrast to recent works that claimed empirical advantages of scalarization, when the model is under-parametrized,  scalarization is inherently incapable of full exploration, especially for those Pareto optimal solutions that strike the balanced trade-offs between multiple tasks. I will conclude the talk by briefly discussing the extension of our results to general nonlinear neural networks and our recent work on using online Chebyshev scalarization to controllably steer the search of Pareto optimal solutions.
                </p>
            </div>
            <div class="day" onclick="toggleDetails('day106')">Bio</div>
            <div id="day106" class="details-content">
                <p>
                    Dr. Han Zhao is an Assistant Professor of Computer Science at the University of Illinois Urbana-Champaign (UIUC). He is also an Amazon Scholar at Amazon AI. Dr. Zhao earned his Ph.D. degree in machine learning from Carnegie Mellon University. His research interest is centered around trustworthy machine learning, with a focus on algorithmic fairness, robust generalization and model interpretability. He has been named a Kavli Fellow of the National Academy of Sciences and has been selected for the AAAI New Faculty Highlights program. His research has been recognized through a Google Research Scholar Award, an Amazon Research Award, and a Meta Research Award.
                </p>
            </div>

            <h4>ï¼ˆå…«ï¼‰16:30-17:00 æ¢å®µï¼ˆé¦™æ¸¯ä¸­æ–‡å¤§å­¦ï¼‰</h4>
            <h4 style="font-weight: normal;"><strong>Title</strong>:Simulation-Based Cryptographic Security in a Quantum Era</h4>
            <div class="day" onclick="toggleDetails('day17')">Abstract</div>
            <div id="day17" class="details-content">
                <p>
                    Quantum computing is progressing rapidly from theoretical exploration to practical realization. From a cryptographic perspective, the dark side of this "quantum moon" poses potentially catastrophic challenges to classical security assumptions. A straightforward response to quantum threats is to replace classical hardness assumptions with quantum-resistant alternatives. While this approach is sufficient for simple primitives such as standard commitments and encryption schemes, it falls short in more advanced cryptographic tasksâ€”particularly those whose security is defined via simulation. Notable examples include zero-knowledge proofs and secure multi-party computation. This talk will explore the foundational challenges in achieving simulation-based security against quantum adversaries. The goal is to provide a clear and insightful overview of this rapidly evolving area, presenting recent technical advances, as well as major open problems that define the current research frontier.
                </p>
            </div>
            <div class="day" onclick="toggleDetails('day107')">Bio</div>
            <div id="day107" class="details-content">
                <p>
                    Xiao Liang's is an Assistant Professor at the Chinese University of Hong Kong. His research interests lie in Cryptography and its intersections with related fields such as Quantum Computing, Computational Complexity Theory, and Computer Security. His work has concentrated on theoretical fundamentals, including Zero-Knowledge Protocols, Secure Multi-Party Computation, Non-Malleability, and Digital Signatures, as well as their practical applications. His research has been published at respected conferences (e.g., FOCS, CRYPTO, and ICALP).  Prior to his appointment at CUHK, Xiao Liang served as a postdoctoral fellow at NTT Research, Rice University, and Indiana University Bloomington. He holds a Ph.D. in Computer Science and an M.Sc. in Applied Mathematics from Stony Brook University, and a Bachelor of Economics from Beijing Institute of Technology.
                </p>
            </div>

            <h4>ï¼ˆä¹ï¼‰17:00-17:30 æå…ƒï¼ˆå¤æ—¦å¤§å­¦ï¼‰</h4>
            <h4 style="font-weight: normal;"><strong>Title</strong>:Average-Case Deterministic Query Complexity of Boolean Functions with Fixed Weight</h4>
            <div class="day" onclick="toggleDetails('day19')">Abstract</div>
            <div id="day19" class="details-content">
                <p>
                    We study the $\textit{average-case deterministic query complexity}$ of boolean functions under a uniform input distribution, denoted by  $\avgq(f)$,  the minimum average depth of zero-error decision trees that compute a boolean function $f$. This measure has found several applications across diverse fields, yet its understanding is limited.  We study boolean functions with fixed weight, where weight is defined as the number of inputs on which the output is $1$. We prove \(\avgq(f) \le \max \{ \log \frac{\wt(f)}{\log n} + O(\log \log \frac{\wt(f)}{\log n}), O(1) \}\) for every $n$-variable boolean function $f$, where $\wt(f)$ denotes the weight. For any $4\log n \le m(n) \le 2^{n-1}$, we prove the upper bound is tight up to an additive logarithmic term for almost all $n$-variable boolean functions with fixed weight $\wt(f) = m(n)$.   H{\aa}stad's switching lemma or Rossman's switching lemma [Comput. Complexity Conf. 137, 2019] implies $\avgq(f) \leq  n(1 - \frac{1}{O(w)})$ or $\avgq(f) \le n(1 - \frac{1}{O(\log s)})$ for CNF/DNF formulas of width $w$ or size $s$, respectively.  We show there exists a DNF formula of width $w$ and size $\lceil 2^w / w \rceil$ such that $\avgq(f) = n (1 - \frac{\log n}{\Theta(w)})$ for any $w \ge 2\log n$.
                </p>
            </div>
            <div class="day" onclick="toggleDetails('day108')">Bio</div>
            <div id="day108" class="details-content">
                <p>
                    Yuan Li is an assistant professor at Fudan University. Prior to this, he was a software engineer at Google from 2017 to 2021. He received his BSc in Computer Science from Fudan University in 2011 and his PhD in Computer Science from the University of Chicago in 2017. His research interests include computational complexity and coding theory. He has published papers in conferences and journals such as IEEE Transactions on Information Theory, COCOON, FOCS, SIAM Journal on Computing, Information and Computation, Theoretical Computer Science, and DCC (Designs, Codes and Cryptography).
                </p>
            </div>

            <h4>ï¼ˆåï¼‰17:30-18:00 é™ˆé›ªï¼ˆä¸­å›½ç§‘å­¦æŠ€æœ¯å¤§å­¦ï¼‰</h4>
            <h4 style="font-weight: normal;"><strong>Title</strong>: Sparse LPN and Refuting random XORs</h4>
            <div class="day" onclick="toggleDetails('day21')">Abstract</div>
            <div id="day21" class="details-content">
                <p>
                    The sparse LPN problem is closely related to the classical problem of refuting random $k$-CSP and has been widely used in cryptography as the hardness assumption. Different from the standard LPN that samples random vectors in $\mathbf{F}_2^n$, it samples random $k$-sparse vectors. Because the number of $k$-sparse vectors is ${n \choose k}ï¼œn^k$, sparse LPN has learning algorithms in polynomial time when $m>n^{k/2}$. However, much less is known about learning algorithms for a constant $k$ like 3 and  $mï¼œn^{k/2}$ samples, except the Gaussian elimination algorithm and sum-of-squares algorithms. We provide a learning algorithm in $e^{\tilde{O}(\eta \cdot n^{\frac{\delta+1}{2}})}$ time given $\delta \in (0,1)$ and $m=\max\{1,\frac{\eta \cdot n^{\frac{\delta+1}{2}}}{k^2}\} \cdot n^{1+(1-\delta)\cdot \frac{k-1}{2}}$ samples. This improves previous learning algorithms in a wide range of parameters. For example, in the classical setting of $k=3$ and $m=n^{1.4}$ \citep{FKO06,ABW10}, our algorithm would be faster than previous approaches for any $\etaï¼œn^{-0.7}$. Joint work with Wenxuan Shu (USTC) and Zhaienhe Zhou (USTC).
                </p>
            </div><div class="day" onclick="toggleDetails('day109')">Bio</div>
            <div id="day109" class="details-content">
                <p>
                    Xue is a faculty member in USTC. He is broadly interested in theoretical computer science. Specific areas include big data algorithms, learning theory and foundations of machine learning, complexity theory, randomized algorithms and pseudorandomness. Previously, I was a postdoc in the theory group of Northwestern University (in USA) and an assistant professor in George Mason University (in USA). Prior to that, I obtained my PhD in the University of Texas at Austin, under the supervision of David Zuckerman, and my bachelor degree from the Yao class of Tsinghua University.
                </p>
            </div>


            <h3 >6 æœˆ 15 æ—¥ ä¸Šåˆ</h3>
            <h4>ï¼ˆåä¸€ï¼‰09:00-09:30 éŸ©æºï¼ˆä¸Šæµ·è´¢ç»å¤§å­¦ï¼‰</h4>
            <h4 style="font-weight: normal;"><strong>Title</strong>:TripleEagle: Simple, Fast and Practical Budget-Feasible Mechanisms for Submodular Valuations</h4>
            <div class="day" onclick="toggleDetails('day23')">Abstract</div>
            <div id="day23" class="details-content">
                <p>
                    We revisit the classical problem of designing Budget-Feasible Mechanisms (BFMs) for submodular valuation functions, which has been extensively studied since the seminal paper of Singer [FOCS'10] due to their wide applications in crowdsourcing and social marketing. We propose ğ–³ğ—‹ğ—‚ğ—‰ğ—…ğ–¾ğ–¤ğ–ºğ—€ğ—…ğ–¾, a novel algorithmic framework for designing BFMs, based on which we present several simple yet effective BFMs that achieve better approximation ratios than the state-of-the-art work. Moreover, our BFMs are the first in the literature to achieve linear query complexity under the value oracle model while ensuring obvious strategyproofness, making them more practical than the previous BFMs. We conduct extensive experiments to evaluate the empirical performance of our BFMs, and the experimental results demonstrate the superiorities of our approach in terms of efficiency and effectiveness compared to the state-of-the-art BFMs.
                </p>
            </div>
            <div class="day" onclick="toggleDetails('day110')">Bio</div>
            <div id="day110" class="details-content">
                <p>
                    Kai Han is currently a professor at the School of Computing and Artificial Intelligence, Shanghai University of Finance and Economics (SUFE). Before joining SUFE, he served as a Distinguished Professor at the School of Computer Science and Technology, Soochow University, and as a professor at the School of Computer Science and Technology, University of Science and Technology of China. His research interests include machine learning, big data processing, algorithmic game theory, and social computing.
                </p>
            </div>

            <h4>ï¼ˆåäºŒï¼‰09:30-10:00 å†¯é€¸ä¸ï¼ˆé¦™æ¸¯ç§‘æŠ€å¤§å­¦ï¼‰</h4>
            <h4 style="font-weight: normal;"><strong>Title</strong>:Persuasive Calibration</h4>
            <div class="day" onclick="toggleDetails('day25')">Abstract</div>
            <div id="day25" class="details-content">
                <p>
                    We introduce and study the persuasive calibration problem, where a principal aims to provide trustworthy predictions about underlying events to a downstream agent to make desired decisions. We adopt the standard calibration framework that regulates predictions to be unbiased conditional on their own value, and thus, they can reliably be interpreted at the face value by the agent. Allowing a small calibration error budget, we aim to answer the following question: what is and how to compute the optimal predictor under this calibration error budget, especially when there exists incentive misalignment between the principal and the agent? We focus on standard  $\ell_t$-norm Expected Calibration Error (ECE) metric.  We develop a general framework by viewing predictors as post-processed versions of perfectly calibrated predictors. Using this framework, we first characterize the structure of the optimal predictor. Specifically, when the principal's utility is event-independent and for $\ell_1$-norm ECE, we show: (1) the optimal predictor is over-(resp. under-) confident for high (resp. low) true expected outcomes, while remaining perfectly calibrated in the middle; (2) the miscalibrated predictions exhibit a collinearity structure with the principal's utility function. On the algorithmic side, we provide a FPTAS for computing approximately optimal predictor for general principal utility and general $\ell_t$-norm ECE. Moreover, for the $\ell_1$ and $\ell_\infty$-norm ECE, we provide polynomial-time algorithms that compute the exact optimal predictor.
                </p>
            </div>
            <div class="day" onclick="toggleDetails('day111')">Bio</div>
            <div id="day111" class="details-content">
                <p>
                    Yiding Feng is an assistant professor at HKUST IEDA. Previously, he worked as a principal researcher at the University of Chicago Booth School of Business, and a postdoctoral researcher at Microsoft Research New England. He received his Ph.D. from the Department of Computer Science at Northwestern University in 2021, and his BS degree from ACM Honors Class at Shanghai Jiao Tong University in 2016. His research focuses on operations research, economics & computation, and theoretical computer science. He was the recipient of the INFORMS Auctions and Market Design (AMD) Michael H. Rothkopf Junior Researcher Paper Prize (second place), and the APORS Young Researcher Best Paper Award.
                </p>
            </div>

            <h4>ï¼ˆåä¸‰ï¼‰11:00-11:30 æå¸…ï¼ˆä¸Šæµ·äº¤é€šå¤§å­¦ï¼‰</h4>
            <h4 style="font-weight: normal;"><strong>Title</strong>:Optimal Algorithm for Max-Min Fair Bandit</h4>
            <div class="day" onclick="toggleDetails('day27')">Abstract</div>
            <div id="day27" class="details-content">
                <p>
                    Multi-player multi-armed bandit (MP-MAB) has been widely studied owing to its diverse applications across numerous domains. We consider an MP-MAB problem where $N$ players compete for $K$ arms in $T$ rounds. The reward distributions are heterogeneous where each player has a different expected reward for the same arm. When multiple players select the same arm, they collide and obtain zero rewards. In this paper, our target is to find the max-min fairness matching that maximizes the reward of the player who receives the lowest reward. This paper improves the existing max-min regret upper bound of $O(\exp(1/\Delta) + K^3 \log T\log \log T)$. More specifically, our decentralized fair elimination algorithm (DFE) deals with heterogeneity and collision carefully and attains a regret upper bound of $O((N^2+K)\log T / \Delta)$, where $\Delta$ is the minimum reward gap between max-min value and sub-optimal arms. In addition, this paper also provides an $\Omega(\max\{N^2, K\} \log T / \Delta)$ regret lower bound for this problem, which indicates that our algorithm is optimal with respect to key parameters $T, N, K$, and $\Delta$. Additional numerical experiments also show the efficiency and improvement of our algorithms. This work is accepted in ICML 2025.
                </p>
            </div>
            <div class="day" onclick="toggleDetails('day112')">Bio</div>
            <div id="day112" class="details-content">
                <p>
                    æå¸…å‰¯æ•™æˆç ”ç©¶å¯è‡ªä¸»å†³ç­–é€‚åº”åŠ¨æ€ç¯å¢ƒçš„å¼ºåŒ–å­¦ä¹ ç†è®ºä¸æ–¹æ³•ï¼Œä»»ä¸Šæµ·äº¤é€šå¤§å­¦çº¦ç¿°Â·éœæ™®å…‹ç½—å¤«ç‰¹è®¡ç®—æœºç§‘å­¦ä¸­å¿ƒå‰¯ä¸»ä»»ï¼Œè¿„ä»Šå…±å‘è¡¨å­¦æœ¯è®ºæ–‡90+ç¯‡ï¼ŒåŒ…å«ä¸Šæµ·äº¤é€šå¤§å­¦é¦–ç¯‡æœºå™¨å­¦ä¹ ç†è®ºé¡¶ä¼šCOLTè®ºæ–‡ç­‰ï¼Œå…¶ä¸­ç¬¬ä¸€/é€šè®¯ä½œè€…å‘è¡¨CCF-Aç±»è®ºæ–‡40+ç¯‡ï¼Œ10ä½™é¡¹ç†è®ºæå‡æˆæœä»ä¿æŒç†è®ºæœ€ä¼˜ã€‚å¥¹æ‹…ä»»æœºå™¨å­¦ä¹ é¡¶ä¼šICMLã€NeurIPSã€UAIã€ACLã€IJCAIã€AAMASçš„é¢†åŸŸä¸»å¸­ï¼ˆArea Chairï¼‰ä¸é«˜çº§ç¨‹åºå§”å‘˜ä¼šå§”å‘˜ï¼ˆSPCï¼‰ï¼Œå—é‚€äºç¾¤ä½“æ™ºèƒ½é¡¶çº§ä¼šè®®AAMASä¸Šç»™å‡ºå¤šæ™ºèƒ½ä½“åœ¨çº¿å­¦ä¹ ä¸é©¬å°”å¯å¤«åšå¼ˆç†è®ºåŸºç¡€çš„æ•™ç¨‹ï¼ˆè¿ç»­ä¸¤å¹´ï¼‰å’ŒIJCAIä¸Šç»™å‡ºå¤šæ™ºèƒ½ä½“åœ¨çº¿å­¦ä¹ çš„æ•™ç¨‹ï¼Œä¸»æŒå›½è‡ªç„¶é¢ä¸ŠåŸºé‡‘ã€é’å¹´åŸºé‡‘ï¼Œå‚ä¸å›½è‡ªç„¶é‡å¤§ç ”ç©¶è®¡åˆ’ã€ç§‘æŠ€éƒ¨2030æ–°ä¸€ä»£äººå·¥æ™ºèƒ½é‡å¤§é¡¹ç›®ã€‚å¥¹æ›¾è·å¾—AAAI-IAAI Deployed Application Awardã€ä¸Šæµ·å¸‚æ‰¬å¸†äººæ‰è®¡åˆ’ã€ä¸Šæµ·å¾æ±‡å…‰å¯äººæ‰ã€è°·æ­Œåšå£«å¥–å­¦é‡‘ã€é¦™æ¸¯æ”¿åºœå¤–å±•åˆä½œå¥–ã€åä¸ºç«èŠ±å¥–ã€å›½é™…SATç«èµ›å¹¶è¡Œæ±‚è§£èµ›é“é“œç‰Œã€è…¾è®¯ä¼˜ç§€å¯¼å¸ˆå¥–ç­‰ã€‚
                </p>
            </div>

            <h4>ï¼ˆåå››ï¼‰11:30-12:00 é‡‘è€€æ¥ ï¼ˆåä¸ºï¼‰</h4>
            <h4 style="font-weight: normal;"><strong>Title</strong>:Tight regret bounds for fixed price bilateral trade</h4>
            <div class="day" onclick="toggleDetails('day28')">Abstract</div>
            <div id="day28" class="details-content">
                <p>
                    We examine fixed-price mechanisms in bilateral trade through the lens of regret minimization. Our main results are twofold. (i) For independent values, a near-optimal $\widetilde{\Theta}(T^{2/3})$ tight bound for Global Budget Balance fixed-price mechanisms with two-bit/one-bit feedback. (ii) For correlated/adversarial values, a near-optimal $\Omega(T^{3/4})$ lower bound for Global Budget Balance fixed-price mechanisms with two-bit/one-bit feedback, which improves the best known $\Omega(T^{5/7})$ lower bound obtained in the work BCCF24 and, up to polylogarithmic factors, matches the $\widetilde{\mathcal{O}}(T^{3 / 4})$ upper bound obtained in the same work. Our work in combination with the previous works CCCFL24mor, CCCFL24jmlr, AFF24, BCCF24 (essentially) gives a thorough understanding of regret minimization for fixed-price bilateral trade. En route, we have developed two technical ingredients that might be of independent interest: (i) A novel algorithmic paradigm, called fractal elimination, to address one-bit feedback and independent values. (ii) A new lower-bound construction with novel proof techniques, to address the Global Budget Balance constraint and correlated values.
                </p>
            </div>
            <div class="day" onclick="toggleDetails('day113')">Bio</div>
            <div id="day113" class="details-content">
                <p>
                    Yaonan Jin is a full-time researcher at the Huawei TCS Lab (lead by Pinyan Lu). His research interests encompass Theoretical Computer Science, with an emphasis on Algorithmic Economics. Before joining Huawei, he obtained his PhD from Columbia University in 2023 (advised by Xi Chen and Rocco Servedio). Before that, he obtained his MPhil from Hong Kong University of Science and Technology in 2019 (advised by Qi Qi) and his BEng from Shanghai Jiao Tong University in 2017.
                </p>
            </div>
        </div>

        <div class="organization" id="organization">
            <div style="height: 50px;"></div>
            <h2>ç»„ç»‡æœºæ„</h2>
            <p>
                ä¸»åŠå•ä½ï¼šç†è®ºè®¡ç®—æœºç§‘å­¦ç ”ç©¶ä¸­å¿ƒï¼ˆITCSï¼‰
            </p>
            <p>
                ååŠå•ä½ï¼šè®¡ç®—ç»æµäº¤å‰ç§‘å­¦æ•™è‚²éƒ¨é‡ç‚¹å®éªŒå®¤ã€è®¡ç®—æœºä¸äººå·¥æ™ºèƒ½æ™ºå­¦é™¢
            </p>
            <p>
                è”ç³»é‚®ç®±:liang.huili@mail.shufe.edu.cn
            </p>
        </div>
        <div style="height: 30px;"></div>
    </div>
</body>
</html>
